{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pmldl.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ8Bqysju5kV"
      },
      "source": [
        "# Installation and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG9P13jQpVpn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93528e68-8927-48bc-b9b3-8341d010b4e3"
      },
      "source": [
        "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b0.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-17 20:29:31--  https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b0.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 142.251.8.128, 2404:6800:4008:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 156407520 (149M) [application/octet-stream]\n",
            "Saving to: ‘noisy_student_efficientnet-b0.tar.gz’\n",
            "\n",
            "noisy_student_effic 100%[===================>] 149.16M  34.7MB/s    in 4.3s    \n",
            "\n",
            "2021-11-17 20:29:36 (34.7 MB/s) - ‘noisy_student_efficientnet-b0.tar.gz’ saved [156407520/156407520]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnfT1bG4tsqv"
      },
      "source": [
        "!tar -xf noisy_student_efficientnet-b0.tar.gz"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWx73SDNtx0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a7069f-cd7d-43cb-d174-47579109cea4"
      },
      "source": [
        "!python efficientnet_weight_update_util.py --model b0 --notop --ckpt noisy_student_efficientnet-b0/model.ckpt --o efficientnetb0_notop.h5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-17 20:29:44.430893: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n",
            "check variables match in each block\n",
            "blocks_0 and block1a match.\n",
            "blocks_1 and block2a match.\n",
            "blocks_2 and block2b match.\n",
            "blocks_3 and block3a match.\n",
            "blocks_4 and block3b match.\n",
            "blocks_5 and block4a match.\n",
            "blocks_6 and block4b match.\n",
            "blocks_7 and block4c match.\n",
            "blocks_8 and block5a match.\n",
            "blocks_9 and block5b match.\n",
            "blocks_10 and block5c match.\n",
            "blocks_11 and block6a match.\n",
            "blocks_12 and block6b match.\n",
            "blocks_13 and block6c match.\n",
            "blocks_14 and block6d match.\n",
            "blocks_15 and block7a match.\n",
            "skipping variable normalization/mean:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
            "skipping variable normalization/variance:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
            "skipping variable normalization/count:0: normalization is a layerin keras implementation, but preprocessing in TF implementation.\n",
            "309/312 weights updated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXOGxusTvYRP",
        "outputId": "27fe80ba-517a-4f01-dbe9-5fe76ad18d1c"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 4.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-2tZVEdwb4O"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTk8f2XVNjyt"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# shutil.rmtree('data')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dih9avcIeF-W"
      },
      "source": [
        "os.mkdir('data')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k7MXEy4Nzyc"
      },
      "source": [
        "!unrar x data/imgs.rar data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5rOt50Vwew4"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "data_path = 'data/'\n",
        "json_files = json_files = [pos_json for pos_json in listdir(data_path) if pos_json.endswith('.json')]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOnIk_j0C0qm"
      },
      "source": [
        "import json\n",
        "df = pd.DataFrame(columns=['image_location', 'point1', 'point2'])\n",
        "\n",
        "for json_file in json_files:\n",
        "  with open(data_path+json_file) as jf:\n",
        "      d = json.load(jf)\n",
        "      arr = list(eval(d['eye_details']['look_vec']))\n",
        "      df = df.append({'image_location': data_path+json_file.split('.')[0]+'.jpg', 'point1': arr[0], 'point2': arr[1]}, ignore_index=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Qf0B8Tp9ExWr",
        "outputId": "4f6755b1-e7c4-45da-9207-cd627a5ec35c"
      },
      "source": [
        "df"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_location</th>\n",
              "      <th>point1</th>\n",
              "      <th>point2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/1111.jpg</td>\n",
              "      <td>0.9172</td>\n",
              "      <td>-0.0279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/855.jpg</td>\n",
              "      <td>0.3415</td>\n",
              "      <td>-0.3774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/91.jpg</td>\n",
              "      <td>0.7313</td>\n",
              "      <td>0.2205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/325.jpg</td>\n",
              "      <td>0.2839</td>\n",
              "      <td>-0.3854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/144.jpg</td>\n",
              "      <td>-0.1043</td>\n",
              "      <td>0.0695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1153</th>\n",
              "      <td>data/1086.jpg</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>-0.5430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1154</th>\n",
              "      <td>data/1039.jpg</td>\n",
              "      <td>0.6823</td>\n",
              "      <td>0.0080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1155</th>\n",
              "      <td>data/731.jpg</td>\n",
              "      <td>0.2550</td>\n",
              "      <td>-0.0588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156</th>\n",
              "      <td>data/237.jpg</td>\n",
              "      <td>0.1189</td>\n",
              "      <td>0.5486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>data/129.jpg</td>\n",
              "      <td>-0.6343</td>\n",
              "      <td>0.0235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1158 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_location  point1  point2\n",
              "0     data/1111.jpg  0.9172 -0.0279\n",
              "1      data/855.jpg  0.3415 -0.3774\n",
              "2       data/91.jpg  0.7313  0.2205\n",
              "3      data/325.jpg  0.2839 -0.3854\n",
              "4      data/144.jpg -0.1043  0.0695\n",
              "...             ...     ...     ...\n",
              "1153  data/1086.jpg  0.0045 -0.5430\n",
              "1154  data/1039.jpg  0.6823  0.0080\n",
              "1155   data/731.jpg  0.2550 -0.0588\n",
              "1156   data/237.jpg  0.1189  0.5486\n",
              "1157   data/129.jpg -0.6343  0.0235\n",
              "\n",
              "[1158 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mPJLSbxGfE"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoaNgOx9xIW2"
      },
      "source": [
        "# General libraries\n",
        "import pandas as pd  #For working with dataframes\n",
        "import numpy as np   #For working with image arrays\n",
        "import cv2          #For transforming image\n",
        "import matplotlib.pyplot as plt  #For representation\n",
        "#For model building\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, utils\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn import functional as F\n",
        "from skimage import io, transform\n",
        "from torch.optim import lr_scheduler\n",
        "from skimage.transform import AffineTransform, warp"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbbWP1Gfz_Yr"
      },
      "source": [
        "class MyData(Dataset):\n",
        "    def __init__(self, df, train=True, transform=None):\n",
        "        images = []\n",
        "        for image in df['image_location']:\n",
        "          img = Image.open(image)\n",
        "          type(img)\n",
        "          images.append(img)\n",
        "        #Setting labels\n",
        "        label_point1=df['point1']\n",
        "        label_point2=df['point2']\n",
        "        \n",
        "        #Splitting the data into train and validation set\n",
        "        X_train, X_test, y_train_point1, y_test_point1,  y_train_point2,\\\n",
        "        y_test_point2 = train_test_split(images, label_point1, label_point2, test_size=0.2)\n",
        "        \n",
        "        if train==True: \n",
        "            self.x=X_train\n",
        "            self.y_point1=y_train_point1\n",
        "            self.y_point2=y_train_point2\n",
        "        else:\n",
        "            self.x=X_test\n",
        "            self.y_point1=y_test_point1\n",
        "            self.y_point2=y_test_point2            \n",
        "        \n",
        "        #Applying transformation\n",
        "        self.transform=transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image=self.x[idx]\n",
        "        label1=np.array([self.y_point1.iloc[idx]]).astype('float')\n",
        "        label2=np.array([self.y_point2.iloc[idx]]).astype('float')\n",
        "        \n",
        "        sample={'image': image, 'label_point1': label1,\\\n",
        "                'label_point2': label2}\n",
        "        \n",
        "        #Applying transformation\n",
        "        if self.transform:\n",
        "            sample={'image': self.transform(image), 'label_point1': label1,\\\n",
        "                'label_point2': label2}\n",
        "            \n",
        "        return sample"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j-KuMTSRUqZ",
        "outputId": "720a3575-adbe-405b-d2e5-d1186226ab97"
      },
      "source": [
        "a = MyData(df, train=True, transform=transforms)\n",
        "a.__getitem__(2)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': tensor([[[0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          ...,\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804]],\n",
              " \n",
              "         [[0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          ...,\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804]],\n",
              " \n",
              "         [[0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          ...,\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.3804, 0.3804, 0.3804,  ..., 0.3804, 0.3804, 0.3804]]]),\n",
              " 'label_point1': array([0.7599]),\n",
              " 'label_point2': array([-0.301])}"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0k59I_5G1yI"
      },
      "source": [
        "transforms = T.Compose([\n",
        "    T.Resize((128, 128)),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoKdnO89HPz1",
        "outputId": "13db45e9-74ec-40b8-fdb5-af1c51259757"
      },
      "source": [
        "train_data = MyData(df, train=True, transform=transforms)\n",
        "test_data = MyData(df, train=False, transform=transforms)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=50, shuffle=True, num_workers=4)\n",
        "test_dataloader = DataLoader(test_data, batch_size=50, shuffle=True, num_workers=4)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nyodM-xIQ0i"
      },
      "source": [
        "class CNN1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN1, self).__init__()\n",
        "        self.model = models.efficientnet_b0(pretrained=True)\n",
        "        self.fc1 = nn.Linear(1280, 1)  #For age class\n",
        "        self.fc2 = nn.Linear(1280, 1)    #For gender class\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
        "        label1 = self.fc1(x)\n",
        "        label2 = self.fc2(x)\n",
        "        return {'label1': label1, 'label2': label2}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10_151IJKnJ8"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjVCXPyIKqPD"
      },
      "source": [
        "#Setting model and moving to device\n",
        "model_CNN = CNN1().to(device)\n",
        "#For binary output:gender\n",
        "loss = nn.MSELoss()\n",
        "optimizer = optim.SGD(model_CNN.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOCh2qNJK0CW"
      },
      "source": [
        "def train_model(model, loss_func, optimizer, n_epochs=25):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "    for epoch in range(1, n_epochs):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        # train the model #\n",
        "        model.train()\n",
        "        for batch_idx, sample_batched in enumerate(train_dataloader):\n",
        "            # importing data and moving to GPU\n",
        "            image, label1, label2 = sample_batched['image'].to(device),\\\n",
        "                                             sample_batched['label_point1'].to(device),\\\n",
        "                                              sample_batched['label_point2'].to(device)  \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            output=model(image)\n",
        "            label1_hat=output['label1']\n",
        "            label2_hat=output['label2']        \n",
        "            # calculate loss\n",
        "            loss1=loss_func(label1_hat, label1.squeeze().float())\n",
        "            loss2=loss_func(label2_hat, label2.squeeze().float())   \n",
        "            loss=loss1+loss2\n",
        "            # back prop\n",
        "            loss.backward()\n",
        "            # grad\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            if batch_idx % 50 == 0:\n",
        "                print('Epoch %d, Batch %d loss: %.6f' %\n",
        "                  (epoch, batch_idx + 1, train_loss))\n",
        "        # validate the model #\n",
        "        model.eval()\n",
        "        for batch_idx, sample_batched in enumerate(test_dataloader):\n",
        "            image, label1, label2 = sample_batched['image'].to(device),\\\n",
        "                                             sample_batched['label_point1'].to(device),\\\n",
        "                                              sample_batched['label_point2'].to(device) \n",
        "            output = model(image)\n",
        "            label1_hat=output['label1']\n",
        "            label2_hat=output['label2']               \n",
        "            # calculate loss\n",
        "            loss1=loss_func(label1_hat, label1.squeeze())\n",
        "            loss2=loss_func(label2_hat, label2.squeeze())\n",
        "            loss=loss1+loss2\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "        \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, train_loss, valid_loss))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss < valid_loss_min:\n",
        "            torch.save(model, 'model.pt')\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            valid_loss_min = valid_loss\n",
        "    # return trained model\n",
        "    return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtkzHI4hUmzf"
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB3tO9w1LjZb",
        "outputId": "c83c81da-24c9-4d6e-ddee-940ebc8204a1"
      },
      "source": [
        "model_conv=train_model(model_CNN, loss, optimizer)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 1 loss: 0.468952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([26])) that is different to the input size (torch.Size([26, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.400282 \tValidation Loss: 0.401379\n",
            "Validation loss decreased (inf --> 0.401379).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Batch 1 loss: 0.350377\n",
            "Epoch: 2 \tTraining Loss: 0.366208 \tValidation Loss: 0.363178\n",
            "Validation loss decreased (0.401379 --> 0.363178).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.371155\n",
            "Epoch: 3 \tTraining Loss: 0.349809 \tValidation Loss: 0.361622\n",
            "Validation loss decreased (0.363178 --> 0.361622).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 0.368379\n",
            "Epoch: 4 \tTraining Loss: 0.341572 \tValidation Loss: 0.345551\n",
            "Validation loss decreased (0.361622 --> 0.345551).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 0.321118\n",
            "Epoch: 5 \tTraining Loss: 0.335691 \tValidation Loss: 0.344003\n",
            "Validation loss decreased (0.345551 --> 0.344003).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 0.347479\n",
            "Epoch: 6 \tTraining Loss: 0.331735 \tValidation Loss: 0.348494\n",
            "Epoch 7, Batch 1 loss: 0.309237\n",
            "Epoch: 7 \tTraining Loss: 0.328854 \tValidation Loss: 0.330960\n",
            "Validation loss decreased (0.344003 --> 0.330960).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 0.336635\n",
            "Epoch: 8 \tTraining Loss: 0.333984 \tValidation Loss: 0.335334\n",
            "Epoch 9, Batch 1 loss: 0.317334\n",
            "Epoch: 9 \tTraining Loss: 0.326103 \tValidation Loss: 0.335453\n",
            "Epoch 10, Batch 1 loss: 0.349035\n",
            "Epoch: 10 \tTraining Loss: 0.326628 \tValidation Loss: 0.320810\n",
            "Validation loss decreased (0.330960 --> 0.320810).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 0.353556\n",
            "Epoch: 11 \tTraining Loss: 0.324759 \tValidation Loss: 0.324172\n",
            "Epoch 12, Batch 1 loss: 0.294589\n",
            "Epoch: 12 \tTraining Loss: 0.324233 \tValidation Loss: 0.331441\n",
            "Epoch 13, Batch 1 loss: 0.315181\n",
            "Epoch: 13 \tTraining Loss: 0.319605 \tValidation Loss: 0.320514\n",
            "Validation loss decreased (0.320810 --> 0.320514).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 0.344337\n",
            "Epoch: 14 \tTraining Loss: 0.318560 \tValidation Loss: 0.309793\n",
            "Validation loss decreased (0.320514 --> 0.309793).  Saving model ...\n",
            "Epoch 15, Batch 1 loss: 0.299436\n",
            "Epoch: 15 \tTraining Loss: 0.316626 \tValidation Loss: 0.319158\n",
            "Epoch 16, Batch 1 loss: 0.337864\n",
            "Epoch: 16 \tTraining Loss: 0.317590 \tValidation Loss: 0.315116\n",
            "Epoch 17, Batch 1 loss: 0.379578\n",
            "Epoch: 17 \tTraining Loss: 0.318420 \tValidation Loss: 0.320199\n",
            "Epoch 18, Batch 1 loss: 0.250992\n",
            "Epoch: 18 \tTraining Loss: 0.318202 \tValidation Loss: 0.313701\n",
            "Epoch 19, Batch 1 loss: 0.334082\n",
            "Epoch: 19 \tTraining Loss: 0.315663 \tValidation Loss: 0.319199\n",
            "Epoch 20, Batch 1 loss: 0.313907\n",
            "Epoch: 20 \tTraining Loss: 0.313075 \tValidation Loss: 0.316117\n",
            "Epoch 21, Batch 1 loss: 0.295899\n",
            "Epoch: 21 \tTraining Loss: 0.322078 \tValidation Loss: 0.314870\n",
            "Epoch 22, Batch 1 loss: 0.306442\n",
            "Epoch: 22 \tTraining Loss: 0.313707 \tValidation Loss: 0.310747\n",
            "Epoch 23, Batch 1 loss: 0.309295\n",
            "Epoch: 23 \tTraining Loss: 0.314864 \tValidation Loss: 0.316283\n",
            "Epoch 24, Batch 1 loss: 0.341982\n",
            "Epoch: 24 \tTraining Loss: 0.314178 \tValidation Loss: 0.312415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do9Pln-9YD4O"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def draw(model):\n",
        "  for batch_idx, sample_batched in enumerate(train_dataloader):\n",
        "    # importing data and moving to GPU\n",
        "    image, label1, label2 = sample_batched['image'].to(device),\\\n",
        "                                      sample_batched['label_point1'].to(device),\\\n",
        "                                      sample_batched['label_point2'].to(device)  \n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    output=model(image)\n",
        "    x=output['label1']\n",
        "    y=output['label2'] \n",
        "    # print(type(x.cpu()))\n",
        "    print(image[0].shape)\n",
        "    cv2.circle(image[0].permute(1, 2, 0), (x, y), 1, (0, 255, 0), 1)\n",
        "\n",
        "    cv2_imshow(image[0])\n",
        "    break"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "lVu6O7-yfDIv",
        "outputId": "02660dc7-055f-42a5-abe4-c67266533765"
      },
      "source": [
        "draw(model_conv)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128, 128])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-60ef876be6d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-d8b430bbfe82>\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# print(type(x.cpu()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument '%s'"
          ]
        }
      ]
    }
  ]
}